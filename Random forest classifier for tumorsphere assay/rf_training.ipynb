{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6os89hph9Z6H"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import time\n",
        "from skimage.measure import label, regionprops, regionprops_table\n",
        "import pandas\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fft_padding(img, kernel):\n",
        "  p = img.shape[0] + kernel.shape[0] - 1\n",
        "  q = img.shape[1] + kernel.shape[1] - 1\n",
        "  new_img = np.zeros((p, q))\n",
        "  new_img[0:img.shape[0], 0:img.shape[1]]=img\n",
        "  new_kernel = np.zeros((p, q))\n",
        "  new_kernel[0:kernel.shape[0], 0:kernel.shape[1]]=kernel\n",
        "  return new_img, new_kernel\n",
        "\n",
        "\n",
        "def convolve(img, kernel, iter):\n",
        "  new_img, new_kernel = fft_padding(img, kernel)\n",
        "  fft_img=np.fft.fft2(new_img)\n",
        "  fft_kernel=np.fft.fft2(new_kernel)\n",
        "  convolved_img=fft_img * (fft_kernel ** iter)\n",
        "  convolved_img=np.round(np.fft.ifft2(convolved_img).real)\n",
        "  return convolved_img\n",
        "\n",
        "\n",
        "def processing(img):\n",
        "  #noise reduction\n",
        "  mean_filter = 1/49 * np.ones((7,7))\n",
        "  smooth_img = convolve(img, mean_filter, 2)\n",
        "\n",
        "  #edge detection\n",
        "  sobel_x = np.array([[-5, 0, 5], [-5, 0, 5], [-5, 0, 5]])\n",
        "  sobel_y = np.array([[-5, -5, -5], [0, 0, 0], [5, 5, 5]])\n",
        "  sobel_x = convolve(smooth_img, sobel_x, 1)\n",
        "  sobel_y = convolve(smooth_img, sobel_y, 1)\n",
        "  gradient = np.sqrt(np.square(sobel_x) + np.square(sobel_y))\n",
        "  thresh, ret=cv2.threshold(gradient, 50, 255, cv2.THRESH_BINARY)\n",
        "  ret=cv2.dilate(ret, (5,5), iterations=2)\n",
        "  ret=cv2.erode(ret, (9,9), iterations=2)\n",
        "  return ret[8:, 8:]"
      ],
      "metadata": {
        "id": "mtegt-Ae9dMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sphere classification\n",
        "#use this cell to classify spheres manually\n",
        "if not 'good_imgs' in locals():\n",
        "  good_imgs = os.listdir(os.getcwd())\n",
        "for img in good_imgs:\n",
        "  if not os.path.isfile(img):\n",
        "    good_imgs.remove(img)\n",
        "\n",
        "properties = ['area','area_bbox',\t'area_convex',\t'area_filled',\t'axis_major_length',\t'axis_minor_length']\n",
        "props_spheres = []\n",
        "props_noise = []\n",
        "\n",
        "for item in good_imgs:\n",
        "  img=cv2.imread(item, 0)\n",
        "  color_img=cv2.imread(item)\n",
        "\n",
        "  processed_img = processing(img)\n",
        "  contours, hierarchy = cv2.findContours(processed_img.astype('uint8'),\\\n",
        "                                         cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  for contour in contours:\n",
        "    if cv2.contourArea(contour) > 200:\n",
        "      cv2.drawContours(color_img, contour, -1, (0,255,0), -1)\n",
        "      x,y,w,h = cv2.boundingRect(contour)\n",
        "      cv2_imshow(color_img[y:y+h, x:x+w])\n",
        "      time.sleep(1)\n",
        "      blank = np.zeros((processed_img.shape))\n",
        "      blank = cv2.drawContours(blank.astype('uint8'), contour, -1, (255, 255, 255), 3)\n",
        "      label_img = label(blank, connectivity=2)\n",
        "      props = regionprops_table(label_img, properties=properties)\n",
        "      verdict = input('approved (1), rejected (0)')\n",
        "      if verdict == '1':\n",
        "        props_spheres.append(props)\n",
        "      else:\n",
        "        props_noise.append(props)\n",
        "      clear_output()"
      ],
      "metadata": {
        "id": "DiGUBcJMAkbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combines and filter the resulting dataframes\n",
        "measures=pandas.DataFrame()\n",
        "for i in props_spheres:\n",
        "  object_df=pandas.DataFrame(i)\n",
        "  category = ['1' * object_df.shape[0]]\n",
        "  object_df=pandas.concat([object_df, pandas.DataFrame(category)], axis=1)\n",
        "  measures=pandas.concat([measures, object_df])\n",
        "\n",
        "\n",
        "for j in props_noise:\n",
        "  object_df=pandas.DataFrame(j)\n",
        "  category = ['0' * object_df.shape[0]]\n",
        "  object_df=pandas.concat([object_df, pandas.DataFrame(category)], axis=1)\n",
        "  measures=pandas.concat([measures, object_df])\n",
        "measures=measures.reset_index(drop=True)\n",
        "measures.to_csv('measures.csv')"
      ],
      "metadata": {
        "id": "VwhMGmULA0Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the random forest model\n",
        "if not 'measures.csv' in locals():\n",
        "  measures = pandas.read_csv('measures.csv')\n",
        "\n",
        "properties = ['area','area_bbox',\t'area_convex',\t'area_filled',\\\n",
        "              'axis_major_length',\t'axis_minor_length']\n",
        "\n",
        "y = measures['0']\n",
        "y.head()\n",
        "X= measures[properties]\n",
        "rf_model = RandomForestClassifier()\n",
        "test_accuracy = []\n",
        "for k in range(100):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify=y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=k)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    row = (rf_model.score(X_test, y_test), k)\n",
        "    test_accuracy.append(row)\n",
        "    print(f\"Train accuracy - :{rf_model.score(X_train, y_train):.3f}\")\n",
        "    print(f\"Test accuracy - :{rf_model.score(X_test, y_test):.3f}\")\n",
        "\n",
        "print(max(test_accuracy, key= lambda x: x[0]))\n",
        "chosen_k = max(test_accuracy, key= lambda x: x[0])[1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify=y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=chosen_k)\n",
        "rf_model.fit(X_train, y_train)\n",
        "pickle.dump(rf_model, open('rf_model.sav', 'wb'))"
      ],
      "metadata": {
        "id": "K0Zi46u7A4lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('rf_model.sav')\n",
        "files.download('measures.csv')"
      ],
      "metadata": {
        "id": "FofJmvuXA75O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}